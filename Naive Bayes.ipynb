{
 "metadata": {
  "name": "",
  "signature": "sha256:779f2ae548028264c65cca03ecbd17b268a979a0bc72265c51c2d3634bf757c7"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Test Naive Bayes text classification on the NLTK Reuters collection."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "1. Implement the two algorithms from Figure 13.2 from MRS.\n",
      "    Of course you use the data structures already provided by NLTK and use nltk's FreqDist or ConditionalFreqDist methods for counting words.\n",
      "2. Train a classifier for each Reuters category using the training examples. Use add-one smoothing.\n",
      "3. Test your classifiers using the test examples. Give a useful output. That is\n",
      "    1. Compute precision, recall and F1 for each category, and also average them. Choose 5-10 good categories and plot the values for these categories seperately\n",
      "    2. Train a new classifier by using both bigrams AND unigrams as features. Evaluate it. Does it work better? On some categories?\n",
      "4. Can you improve your classifier by doing feature selection? Use the mutual information measure from section 13.5.1. Choose 5 Reuters categories and for each print the top 10 words with the highest score and the top 10 with the lowest score. Just like in Figure 13.7. Does it make sense?\n",
      "6. Now train your classifiers using a different type of smoothing. You can use Bayesian smoothing or Jellinek-Mercer smoothing. See page 226 in MRS. Do you get better results?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk.corpus import reuters"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ids = reuters.fileids()\n",
      "id_count = len(ids)\n",
      "print str(id_count) + \" ids. E.g.: \" + str(ids[:3])\n",
      "\n",
      "cats = reuters.categories()\n",
      "cat_count = len(cats)\n",
      "print str(cat_count) + \" cats. E.g.: \" + str(cats[:3])\n",
      "\n",
      "words = reuters.words()\n",
      "word_count = len(words)\n",
      "print str(word_count) + \" words. E.g.: \" + str(words[:3])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "10788 ids. E.g.: [u'test/14826', u'test/14828', u'test/14829']\n",
        "90 cats. E.g.: [u'acq', u'alum', u'barley']"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1720901 words. E.g.: [u'ASIAN', u'EXPORTERS', u'FEAR']"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_ids = [i for i in ids if i.startswith(\"training/\")]\n",
      "train_id_count = len(train_ids)\n",
      "print str(train_id_count) + \" training documents\"\n",
      "\n",
      "test_ids = [i for i in ids if i.startswith(\"test/\")]\n",
      "test_id_count = len(test_ids)\n",
      "print str(test_id_count) + \" test documents\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "7769 training documents\n",
        "3019 test documents\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vocab = set([word.lower() for word in words])\n",
      "vocab_count = len(vocab)\n",
      "print str(vocab_count) + \" words in vocab\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "31078 words in vocab\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    }
   ],
   "metadata": {}
  }
 ]
}